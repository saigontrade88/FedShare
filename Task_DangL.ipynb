{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saigontrade88/FedShare/blob/main/Task_DangL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfLyTPrzSyE1",
        "outputId": "59412d9b-fc4d-45a9-da06-d383e940b861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive/ColabNotebooks/')"
      ],
      "metadata": {
        "id": "5EXa3SR5TXT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd #linux"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy7hGaIWXmeH",
        "outputId": "f4c2fb05-986d-451c-d6e1-09f6a424b967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al #linux"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHiyXD8kX2VU",
        "outputId": "7cd7903d-3fd1-4d25-99df-00e81a9ddb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24\n",
            "drwxr-xr-x 1 root root 4096 Jun 21 14:32 .\n",
            "drwxr-xr-x 1 root root 4096 Jun 21 14:29 ..\n",
            "drwxr-xr-x 4 root root 4096 Jun 16 18:15 .config\n",
            "-rw-r--r-- 1 root root 3724 Jun 21 14:31 cw.py\n",
            "drwxr-xr-x 2 root root 4096 Jun 21 14:32 .ipynb_checkpoints\n",
            "-rw-r--r-- 1 root root    0 Jun 21 14:32 run_utils.py\n",
            "drwxr-xr-x 1 root root 4096 Jun 16 18:16 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "gekWr539OUZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8fd78d83-3c70-4dfe-8fb2-9d6d5298617b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install torch==0.3.1\n",
        "#you need to print out the torch's version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfozTyLNNNr0",
        "outputId": "e1936556-fb5b-4ce0-bb30-5fb363a5c174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.3.1 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==0.3.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from binascii import hexlify\n",
        "import torch\n",
        "import cw\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import pickle\n",
        "from torch import nn\n",
        "\n",
        "# Source and reference\n",
        "\n",
        "#https://github.com/kkew3/pytorch-cw2\n",
        "\n",
        "#You need to download the MNIST dataset. Reference:\n",
        "\n",
        "#1) FedShare_AT_v14_PGD_Gaussian_SL_noniid_automation.py\n",
        "\n",
        "#2) The Skitlearn and Pytorch textbook\n",
        "\n",
        "# Need to install a virtual enviroment\n",
        "#\n",
        "#### Insert your code here #########\n",
        "\n",
        "image_path = '/content'\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_train_dataset = torchvision.datasets.MNIST(\n",
        "            root=image_path,\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transform)\n",
        "mnist_test_dataset = torchvision.datasets.MNIST(\n",
        "    root=image_path, train=False, download=False,\n",
        "    transform=transform)\n",
        "\n",
        "batch_size = 100\n",
        "torch.manual_seed(1)\n",
        "train_dl = DataLoader(mnist_train_dataset,\n",
        "                      batch_size, shuffle=True)\n",
        "\n",
        "#create a dataloader based on MNIST dataset, with a small input of 100 training examples only.\n",
        "# The ultimate goal is to save the whole training set of MNIST dataset of 60,000 examples.\n",
        "\n",
        "\n",
        "##### End your code##################\n",
        "#mean and std are both 3-tuples of floats.\n",
        "#mean=(0.0, 0.13092535192648502) # for colorful image, a RGB image. MNIST is gray scale, you need a float value\n",
        "\n",
        "#std=(0.1, 0.3084485240270358) # you need a float value.\n",
        "\n",
        "#inputs_box = (min((0 - m) / s for m, s in zip(mean, std)),\n",
        "#              max((1 - m) / s for m, s in zip(mean, std)))\n",
        "\n",
        "# an untargeted adversary\n",
        "\n",
        "adversary = cw.L2Adversary(targeted=False,\n",
        "                            confidence=0.0,\n",
        "                            search_steps=10,\n",
        "                            optimizer_lr=5e-4)\n",
        "\n",
        "inputs, targets = next(iter(train_dl))\n",
        "\n",
        "#### Insert your code here #########\n",
        "\n",
        "#Need to define the model named 'net'\n",
        "#Need to define the variable 'targets'\n",
        "\n",
        "class net(nn.Module): #this is a deep learning's model. it is a nested function. Pytorch they have built-in library to define.\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Conv2d(1, 100, (3, 3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(100, 200, (3, 3)),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(200*(28-4)*(28-4), 10),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "targets == [1] #mnist, we have 10 classes\n",
        "\n",
        "\n",
        "##### End your code##################\n",
        "\n",
        "adversarial_examples = adversary(net(),\n",
        "                                 inputs,\n",
        "                                 targets,\n",
        "                                 to_numpy=False)\n",
        "\n",
        "#### Insert your code here #########\n",
        "\n",
        "#Need to save 'adversarial_examples' variable into a file with extension npy (Numpy)\n",
        "\n",
        "with open('adversarial_examples.npy', 'wb') as f:\n",
        "     pickle.dump(adversarial_examples, f)\n",
        "\n",
        "##### End your code##################\n"
      ],
      "metadata": {
        "id": "5H3NFmJLL0-V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "4285559b-0478-41d4-f3bf-40748dad9b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using scale consts: [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a437ef749fa2>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m##### End your code##################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m adversarial_examples = adversary(net(),\n\u001b[0m\u001b[1;32m     87\u001b[0m                                  \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                                  \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cw.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, inputs, targets, to_numpy)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptim_step\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpert_norms_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpert_outputs_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvxs_np\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                     self._optimize(model, optimizer, inputs_tanh_var,\n\u001b[0m\u001b[1;32m    291\u001b[0m                                    \u001b[0mpert_tanh_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_oh_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                                    scale_consts_var)\n",
            "\u001b[0;32m/content/cw.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(self, model, optimizer, inputs_tanh_var, pert_tanh_var, targets_oh_var, c_var)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# Make some records in python/numpy on CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_loss_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mpert_norms_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_var2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperts_norm_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mpert_outputs_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_var2numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpert_outputs_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cw\n",
        "\n",
        "inputs_box = (min((0 - m) / s for m, s in zip(mean, std)),\n",
        "              max((1 - m) / s for m, s in zip(mean, std)))\n",
        "# an untargeted adversary\n",
        "adversary = cw.L2Adversary(targeted=False,\n",
        "                           confidence=0.0,\n",
        "                           search_steps=10,\n",
        "                           box=inputs_box,\n",
        "                           optimizer_lr=5e-4)\n",
        "\n",
        "inputs, targets = next(iter(dataloader))\n",
        "adversarial_examples = adversary(net, inputs, targets, to_numpy=False)"
      ],
      "metadata": {
        "id": "Uo-U9pvmN3s0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}